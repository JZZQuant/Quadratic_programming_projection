{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 96, 149,  90,  28,  81, 202]),\n",
       " array([ 92,  32,  93,  83,  78, 138,  55,  75]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# m=np.random.randint(30,40)\n",
    "# n=np.random.randint(50,60)\n",
    "\n",
    "# from scipy import linalg,sparse\n",
    "# x=sparse.random(m,n,density=0.045,format='csr',dtype='float')*100\n",
    "# mat=np.round(x.todense(),decimals=0)\n",
    "\n",
    "# #remove void rows and columns\n",
    "# rs=np.sum(mat,axis=1)\n",
    "# cs=np.sum(mat,axis=0)\n",
    "# rows=np.where(rs!=0)[0]\n",
    "# rows=np.append(rows,m-1)\n",
    "# cols=np.where(cs!=0)[1]\n",
    "# mat=mat[:,cols][rows,:]\n",
    " \n",
    "# rs=np.sum(mat,axis=1)\n",
    "# cs=np.sum(mat,axis=0)\n",
    "\n",
    "# #create supply demand\n",
    "# demands= np.array(mat.sum(axis=1)).T[0]\n",
    "# supplies=np.array(mat.sum(axis=0))[0]\n",
    "# sparse=np.matrix(np.copy(mat), dtype = int)\n",
    "# sparse[sparse>0]=1\n",
    "# # sparse=np.array(sparse)\n",
    "\n",
    "sparse=np.matrix([[0, 0, 0, 1, 0, 1, 0, 1],\n",
    "       [0, 0, 0, 1, 1, 1, 1, 1],\n",
    "       [0, 0, 1, 0, 1, 1, 0, 0],\n",
    "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [1, 1, 1, 0, 0, 0, 0, 0],\n",
    "       [1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "supplies=np.reshape(np.array([92,32,93,83,78,138,55,75], dtype = int), 8)\n",
    "demands=np.array([96,149,90,28,81,202])\n",
    "\n",
    "demands, supplies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "disjoint - add current and exit\n",
    "equal - update existing - no need to subtract existing subsets; no effect on existing subsets; update all supersets as well\n",
    "proper subset - add current and update all supersets\n",
    "proper supersets - add current with updated value using all existing disjoint subsets; Update all supersets as well, if exists\n",
    "overlaps - add current and add new superset\n",
    "'''\n",
    "\n",
    "def update_constraints_list(current_LHS, current_RHS, existing_LHS, existing_RHS, supplies):\n",
    "    \n",
    "    new_LHS = existing_LHS.copy()\n",
    "    new_RHS = existing_RHS.copy()\n",
    "    \n",
    "    bitwise_intersection = current_LHS & new_LHS\n",
    "    \n",
    "    all_disjoint_subsets = get_all_disjoint_subsets(current_LHS, new_LHS, bitwise_intersection)\n",
    "    all_supersets = get_all_supersets(current_LHS, new_LHS, bitwise_intersection)\n",
    "    all_other_overlaps = get_all_overlaps(current_LHS, new_LHS, bitwise_intersection)\n",
    "    \n",
    "    if (current_LHS == existing_LHS).any():\n",
    "        ## constraint with same set already exists\n",
    "        all_supersets = np.append(all_supersets, current_LHS)\n",
    "        for current_constraint in all_supersets:\n",
    "            new_RHS = modify_constraint(current_constraint, current_RHS, new_LHS, new_RHS)\n",
    "        ## exit\n",
    "        \n",
    "    elif all_disjoint_subsets.shape[0] > 0 or all_supersets.shape[0] > 0 or all_other_overlaps.shape[0] > 0:\n",
    "        ## constraint with same set doesn't exist but subsets/supersets exist\n",
    "        ## Update the supersets first\n",
    "        for current_constraint in all_supersets:\n",
    "            new_RHS = modify_constraint(current_constraint, current_RHS, new_LHS, new_RHS)\n",
    "        \n",
    "        ## Update current constraint based on disjoint subsets and add it to constraints list\n",
    "        current_supply = get_supply_for_combination(current_LHS, supplies)\n",
    "        current_demand_including_subset = current_RHS\n",
    "        for current_subset in all_disjoint_subsets:\n",
    "            subset_demand = get_demand_for_existing_constraint(current_subset, new_LHS, new_RHS)\n",
    "            current_demand_including_subset = current_demand_including_subset + subset_demand\n",
    "        current_RHS_including_subset = current_supply - current_demand_including_subset\n",
    "        new_LHS, new_RHS = add_constraint(current_LHS, current_RHS_including_subset, new_LHS, new_RHS)\n",
    "        \n",
    "        ## For oevrlap list keep creating new supersets and add them; skip if such superset already exist\n",
    "        if all_other_overlaps.shape[0] > 0:\n",
    "            for current_overlap in all_other_overlaps:\n",
    "                new_superset_LHS = current_LHS | current_overlap\n",
    "                if np.in1d(new_superset_LHS, all_supersets):\n",
    "                    continue\n",
    "                else:\n",
    "                    overlap_demand = get_demand_for_existing_constraint(current_overlap, new_LHS, new_RHS)\n",
    "                    new_superset_demand = overlap_demand + current_demand_including_subset #add current_B\n",
    "                    new_superset_supply = get_supply_for_combination(new_superset_LHS, supplies)\n",
    "                    new_superset_RHS = new_superset_supply - new_superset_demand #reduce from new_supply\n",
    "                    new_LHS, new_RHS = add_constraint(new_superset_LHS, new_superset_RHS, new_LHS, new_RHS)\n",
    "                    ## exit\n",
    "    else:\n",
    "        ## It is from different island\n",
    "        ## add current constraint\n",
    "        current_supply = get_supply_for_combination(current_LHS, supplies)\n",
    "        current_RHS = current_supply - current_RHS\n",
    "        new_LHS, new_RHS = add_constraint(current_LHS, current_RHS, new_LHS, new_RHS)\n",
    "        ## exit\n",
    "        \n",
    "    new_LHS, new_RHS = remove_redundancy(new_LHS, new_RHS)\n",
    "    \n",
    "    return new_LHS, new_RHS\n",
    "\n",
    "def get_all_disjoint_subsets(current_LHS, existing_LHS, bitwise_intersection):\n",
    "    existing_LHS_subsets = existing_LHS[bitwise_intersection == existing_LHS]\n",
    "    existing_LHS_subsets = np.setdiff1d(existing_LHS_subsets, current_LHS)\n",
    "    existing_LHS_subsets = list(filter(lambda x: np.sum(x & existing_LHS_subsets == x) == 1, existing_LHS_subsets))\n",
    "    return np.array(existing_LHS_subsets) \n",
    "\n",
    "def get_all_supersets(current_LHS, existing_LHS, bitwise_intersection):\n",
    "    existing_LHS_supersets = existing_LHS[bitwise_intersection == current_LHS]\n",
    "    existing_LHS_supersets = np.setdiff1d(existing_LHS_supersets, current_LHS)\n",
    "    return existing_LHS_supersets\n",
    "\n",
    "def get_all_overlaps(current_LHS, existing_LHS, bitwise_intersection):\n",
    "    all_overlaps = existing_LHS[np.logical_and.reduce((bitwise_intersection != 0, bitwise_intersection != existing_LHS, bitwise_intersection != current_LHS))]\n",
    "    removal_set = np.array([0])\n",
    "    for element1 in all_overlaps:\n",
    "        for element2 in all_overlaps:\n",
    "            if element1 & element2 == element1 and element1 != element2 and (element1 | current_LHS[0] == element2 | current_LHS[0]): \n",
    "                #element1 is subset of element2; they are not equal and both have same superset\n",
    "                removal_set = np.append(removal_set, element1)\n",
    "    all_overlaps = np.setdiff1d(all_overlaps, np.unique(removal_set))        \n",
    "    return all_overlaps\n",
    "\n",
    "def add_constraint(current_LHS, current_RHS, existing_LHS, existing_RHS):\n",
    "    new_LHS = np.append(existing_LHS, current_LHS)\n",
    "    new_RHS = np.append(existing_RHS, current_RHS)\n",
    "    return new_LHS, new_RHS\n",
    "\n",
    "def modify_constraint(current_LHS, current_RHS, existing_LHS, existing_RHS):\n",
    "    new_RHS = existing_RHS\n",
    "    new_RHS[np.squeeze(np.array(existing_LHS == current_LHS))] -= current_RHS\n",
    "    return new_RHS\n",
    "\n",
    "def get_supply_for_combination(combination_LHS, supplies):\n",
    "    import math\n",
    "    bit_string = np.zeros(0, dtype = int)\n",
    "    while combination_LHS>0:\n",
    "        bit_string = np.append(bit_string, combination_LHS%2)\n",
    "        combination_LHS = math.floor(combination_LHS/2)\n",
    "    bit_string = np.flip(bit_string, 0)\n",
    "    padding_length = supplies.shape[0] - bit_string.shape[0]\n",
    "    bit_string = np.pad(bit_string, (padding_length,0), 'constant', constant_values=0)\n",
    "    supply_for_combination = np.dot(bit_string, supplies)\n",
    "    return supply_for_combination\n",
    "\n",
    "def get_demand_for_existing_constraint(required_LHS, existing_LHS, existing_RHS):\n",
    "    required_RHS = np.reshape(np.array(existing_RHS[existing_LHS == required_LHS]), 1)\n",
    "    required_supply = get_supply_for_combination(required_LHS, supplies)\n",
    "    required_demand = required_supply - required_RHS\n",
    "    return required_demand\n",
    "\n",
    "def remove_redundancy(all_LHS, all_RHS):\n",
    "    new_LHS = all_LHS\n",
    "    new_RHS = all_RHS\n",
    "    for current_row in range(new_LHS.shape[0]):\n",
    "        current_LHS = new_LHS[current_row]\n",
    "        current_RHS = new_RHS[current_row]\n",
    "        bitwise_intersection = current_LHS & new_LHS\n",
    "        all_supersets = get_all_supersets(current_LHS, new_LHS, bitwise_intersection)\n",
    "        for current_superset in all_supersets:\n",
    "            superset_RHS = new_RHS[np.squeeze(np.array(new_LHS == current_superset))]\n",
    "            if superset_RHS <= current_RHS:\n",
    "                new_LHS[current_row] = 0\n",
    "                new_RHS[current_row] = 0\n",
    "                break\n",
    "    new_RHS = np.delete(new_RHS, np.where(new_LHS == 0))\n",
    "    new_LHS = np.delete(new_LHS, np.where(new_LHS == 0))\n",
    "    return new_LHS, new_RHS\n",
    "\n",
    "## Also redundancy should be checked on the sum of disjoint supersets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (1,) (1,)\n",
      "2 (2,) (2,)\n",
      "3 (3,) (3,)\n",
      "4 (5,) (5,)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "## initial constraints\n",
    "column_count = sparse.shape[1]\n",
    "A = np.concatenate([-1*np.identity(column_count),np.identity(column_count)])\n",
    "b = np.concatenate([np.zeros(column_count), supplies])\n",
    "\n",
    "#sparse = sparse[[0,3],:]\n",
    "\n",
    "## Adding first constraint\n",
    "request_LHS = np.apply_along_axis(lambda x: int(str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").replace(\"\\n\", \"\"), 2), 1, sparse)\n",
    "existing_LHS = np.reshape(request_LHS[0], 1)\n",
    "existing_RHS = np.array([np.sum(np.array(sparse[0, :])*supplies) - demands[0]])\n",
    "\n",
    "## Looping for other rows\n",
    "for current_row in range(1, (sparse.shape[0] - 1)):\n",
    "    current_LHS = np.reshape(request_LHS[current_row], 1)\n",
    "    current_RHS = np.reshape(demands[current_row], 1)\n",
    "    existing_LHS, existing_RHS = update_constraints_list(current_LHS, current_RHS, existing_LHS, existing_RHS, supplies)\n",
    "    print(current_row, existing_LHS.shape, existing_RHS.shape)\n",
    "    \n",
    "end_time = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(0, 0, 6833)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31,  63, 128, 224, 255])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([184, 187,  64, 108, 202])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
